<h2 align="center"><b> Advanced topics in optimization: From simple to complex ML systems</b> </h2>

<br>
<br>

<table style="width:100%">  
  <tr>
    <td>Email (instructor): anastasios@rice.edu</td>
    <td align="right">Web: https://akyrillidis.github.io/comp545/</td> 
  </tr>
  <tr>
    <td> </td>
    <td align="right">Email (course): RiceCOMP545@gmail.com</td> 
  </tr>
  <tr>
    <td>Office hours: By appointment </td>
    <td align="right">Class hours: T\TH 14:30 - 15:45</td> 
  </tr>
  <tr>
    <td>Office: DH 3119</td>
    <td align="right">Classroom: DH 1075 </td> 
  </tr>
</table>

<table style="width:100%">  
  <tr> 
    <td align="center"><a href="./Syllabus.pdf">Course Syllabus</a></td>
    <td align="center"><a href="./scribe_template.zip">LaTEX template for scribing</a></td>
  </tr>
</table>

<table style="width:100%">  
  <tr> 
    <td align="left"><a href="http://akyrillidis.github.io/comp545/">Course description</a></td>
    <td align="left"><a href="http://akyrillidis.github.io/comp545/schedule.html">Schedule</a></td> 
    <td align="left"><a href="http://akyrillidis.github.io/comp545/grading.html">Grading policy</a></td> 
    <td align="left"><a href="http://akyrillidis.github.io/comp545/literature.html">Literature</a></td> 
  </tr>
</table>

<table style="width:100%">  
  <col width="25%">
  <col width="75%">  
  <tr>
    <td><b>Lecture 1.</b></td>
  </tr>
  <tr>
    <td>Textbook: </td>
    <td align="left"><b> (None) </b></td>
  </tr>
  <br>
  <tr>
    <td>Other references: </td>
    <td align="left"><b><a href="https://arxiv.org/pdf/1707.06347.pdf">- Proximal policy optimization algorithms</a></b></td>    
  </tr>  
  <tr>
    <td></td>
    <td align="left"><b><a href="https://openai.com/blog/openai-five/">- OpenAI Five</a></b></td>    
  </tr> 
  <tr>
    <td></td>
    <td align="left"><b><a href="https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii">- AlphaStar: Mastering the Real-Time Strategy Game StarCraft II</a></b></td>    
  </tr> 
  <tr>
    <td></td>
    <td align="left"><b><a href="https://arxiv.org/pdf/1903.07291.pdf">- Semantic Image Synthesis with Spatially-Adaptive Normalization</a></b></td> 
  </tr> 
  <tr>
    <td></td>
    <td align="left"><b><a href="https://www.youtube.com/watch?v=p5U4NgVGAwg">- GauGAN: Changing Sketches into Photorealistic Masterpieces </a></b></td> 
  </tr> 
  <tr>
    <td></td>
    <td align="left"><b><a href="https://advances.sciencemag.org/content/5/4/eaav2372">- Combinatorial optimization by simulating adiabatic bifurcations in nonlinear Hamiltonian systems </a></b></td> 
  </tr> 
  <tr>
    <td></td>
    <td align="left"><b><a href="https://www.nature.com/articles/s41586-019-1666-5">- Quantum supremacy using a programmable superconducting processor </a></b></td> 
  </tr> 
  <tr>
    <td></td>
    <td align="left"><b><a href="https://www.ibm.com/blogs/research/2019/10/on-quantum-supremacy/">- On "Quantum" supremacy </a></b></td> 
  </tr> 

</table>

<hr/>


<table style="width:100%">  
  <col width="25%">
  <col width="75%">  
  <tr>
    <td><b>Lecture 1.</b></td>
  </tr>
  <tr>
    <td>Textbook: </td>
    <td align="left"><b> (None) </b></td>
  </tr>
  <br>
  <tr>
    <td>Other references: </td>
    <td align="left"><b><a href="http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf">- Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></b></td>    
  </tr>  
  <tr>
    <td></td>
    <td align="left"><b><a href="https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">- RMSProp algorithm</a></b></td>    
  </tr> 
  <tr>
    <td></td>
    <td align="left"><b><a href="https://arxiv.org/pdf/1412.6980.pdf">- Adam: A method for stochastic optimization</a></b></td>    
  </tr> 
  <tr>
    <td></td>
    <td align="left"><b><a href="https://arxiv.org/pdf/1904.09237.pdf">- On the convergence of adam and beyond</a></b></td> 
  </tr> 
  <tr>
    <td></td>
    <td align="left"><b><a href="https://arxiv.org/pdf/1910.04952.pdf">- Decaying momentum helps neural network training </a></b></td> 
  </tr> 
  <tr>
    <td></td>
    <td align="left"><b><a href="https://arxiv.org/pdf/1810.06801.pdf">- Quasi-hyperbolic momentum and Adam for deep learning
 </a></b></td> 
  </tr> 
  <tr>
    <td></td>
    <td align="left"><b><a href="https://arxiv.org/pdf/1804.00325.pdf">- Aggregated Momentum: Stability Through Passive Damping </a></b></td> 
  </tr> 
  <tr>
    <td></td>
    <td align="left"><b><a href="https://ruder.io/optimizing-gradient-descent/">- An overview of gradient descent optimization algorithms</a></b></td> 
  </tr> 

</table>

<hr/>


