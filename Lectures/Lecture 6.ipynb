{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuclear norm minimization vs. IHT for low-rank matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.palettes import brewer\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import random\n",
    "from numpy import linalg as la\n",
    "\n",
    "from matplotlib import rc\n",
    "#rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "## for Palatino and other serif fonts use:\n",
    "rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)\n",
    "\n",
    "p = 128  # Matrices of size p x p\n",
    "r = 2   # Sparsity level\n",
    "n = np.ceil(5 * p * r)\n",
    "\n",
    "# Generate a pxp-dimensional zero matrix\n",
    "A = np.random.randn(p, r)\n",
    "B = np.random.randn(p, r)\n",
    "X_star = A.dot(B.T)\n",
    "X_star = (1 / la.norm(X_star, 'fro')) * X_star\n",
    "\n",
    "# Generate matrices for the sensing mechanism\n",
    "A = np.zeros((int(n), p, p))\n",
    "for i in range(int(n)):\n",
    "    C = (1/np.sqrt(n)) * np.random.randn(p, p)\n",
    "    A[i, :, :] = C\n",
    "\n",
    "# print(A[1, :, :])\n",
    "# print(np.squeeze(A[i, :, :]))\n",
    "# print(np.squeeze(A[i, :, :]).shape)\n",
    "# print(1/np.sqrt(n))\n",
    "# Observation model\n",
    "y = np.zeros(int(n))\n",
    "\n",
    "for i in range(int(n)):\n",
    "    B = np.squeeze(A[i, :, :])\n",
    "    y[i] = np.trace(B.dot(X_star.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds, eigs\n",
    "\n",
    "# Hard thresholding function\n",
    "def hardThreshold(X, r):\n",
    "    U, S, V = svds(X, k = r)    \n",
    "    S = np.diag(S)\n",
    "    return U.dot(S.dot(V))\n",
    "\n",
    "def l1normProj(x, l):\n",
    "    assert l > 0, \"Radius lambda must be strictly positive (%d <= 0)\" % l\n",
    "    n, = x.shape  \n",
    "    \n",
    "    u = np.abs(x)                               # compute the vector of absolute values\n",
    "    \n",
    "    if u.sum() <= l:                            # check if v is already a solution    \n",
    "        return x\n",
    "    \n",
    "    u = np.sort(x)[::-1]                        # get the array of cumulative sums of a sorted (decreasing) copy of v\n",
    "    cssv = np.cumsum(u)\n",
    "    rho = np.nonzero(u * np.arange(1, n+1) > (cssv - l))[0][-1]   # get the number of > 0 components of the optimal solution\n",
    "    theta = (float(cssv[rho] - l) / rho).clip(min=0)                 # compute the projection by thresholding v using theta          # compute the Lagrange multiplier associated to the simplex constraint\n",
    "    w = (np.abs(x) - theta).clip(min=0)                 # compute the projection by thresholding v using theta\n",
    "    w *= np.sign(x)    \n",
    "        \n",
    "    return w\n",
    "\n",
    "def proj_nuclear_norm(X, l):\n",
    "    U, S, V = la.svd(X)\n",
    "    S = l1normProj(S, l)\n",
    "    S = np.diag(S)\n",
    "    return U.dot(S.dot(V))\n",
    "    \n",
    "# Returns the value of the objecive function\n",
    "def f(y, A, X):\n",
    "    f_value = 0\n",
    "    n = y.shape[0]\n",
    "    for i in range(n):\n",
    "        B = np.squeeze(A[i, :, :])\n",
    "        f_value += 0.5 * (y[i] - np.trace(B.dot(X.T)))**2\n",
    "    return f_value\n",
    "\n",
    "def compute_grad(y, A, X):\n",
    "    n = y.shape[0]\n",
    "    p = A.shape[1]\n",
    "\n",
    "    grad = np.zeros((p, p))\n",
    "    b = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        B = np.squeeze(A[i, :, :])        \n",
    "        b[i] = y[i] - np.trace(B.dot(X.T))\n",
    "    \n",
    "#     print(b)\n",
    "    for i in range(n):\n",
    "        B = np.squeeze(A[i, :, :])\n",
    "        grad += -b[i] * B;\n",
    "    \n",
    "#     print(grad)\n",
    "    return grad\n",
    "\n",
    "def matrix_IHT(y, A, r, eta, iters, epsilon, verbose, X_star):\n",
    "    # Length of original signal\n",
    "    p = A.shape[1]\n",
    "    # Length of measurement vector\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # Initial estimate\n",
    "    X_new = np.zeros((p, p))\n",
    "    \n",
    "    X_list, f_list = [1], [f(y, A, X_new)]\n",
    "\n",
    "    for i in range(iters):\n",
    "        X_old = X_new\n",
    "    \n",
    "        # Compute gradient\n",
    "        grad = compute_grad(y, A, X_old)\n",
    "#         print(grad)\n",
    "        # Perform gradient step\n",
    "        X_temp = X_old - eta * grad    \n",
    "    \n",
    "        # Perform hard thresholding step\n",
    "        X_new = hardThreshold(X_temp, r)\n",
    "    \n",
    "        if (la.norm(X_new - X_old, 'fro') / la.norm(X_new, 'fro')) < epsilon:\n",
    "            break\n",
    "                \n",
    "        # Keep track of solutions and objective values\n",
    "        X_list.append(la.norm(X_new - X_star, 'fro'))\n",
    "        f_list.append(f(y, A, X_new))\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"iter# = \"+ str(i) + \", ||X_new - X_old||_2 = \" + str(la.norm(X_new - X_old, 'fro')))\n",
    "    \n",
    "    print(\"Number of steps:\", len(f_list))\n",
    "    return X_new, X_list, f_list\n",
    "\n",
    "def matrix_nuclear_norm_min(y, A, l, eta, iters, epsilon, verbose, X_star):\n",
    "    # Length of original signal\n",
    "    p = A.shape[1]\n",
    "    # Length of measurement vector\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # Initial estimate\n",
    "    X_new = np.zeros((p, p))\n",
    "    \n",
    "    X_list, f_list = [1], [f(y, A, X_new)]\n",
    "\n",
    "    for i in range(iters):\n",
    "        X_old = X_new\n",
    "    \n",
    "        # Compute gradient\n",
    "        grad = compute_grad(y, A, X_old)\n",
    "    \n",
    "        # Perform gradient step\n",
    "        X_temp = X_old - eta * grad    \n",
    "    \n",
    "        # Perform hard thresholding step\n",
    "        X_new = proj_nuclear_norm(X_temp, l)\n",
    "    \n",
    "        if (la.norm(X_new - X_old, 'fro') / la.norm(X_new, 'fro')) < epsilon:\n",
    "            break\n",
    "                \n",
    "        # Keep track of solutions and objective values\n",
    "        X_list.append(la.norm(X_new - X_star, 'fro'))\n",
    "        f_list.append(f(y, A, X_new))\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"iter# = \"+ str(i) + \", ||X_new - X_old||_2 = \" + str(la.norm(X_new - X_old, 'fro')))\n",
    "    \n",
    "    print(\"Number of steps:\", len(f_list))\n",
    "    return X_new, X_list, f_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter# = 0, ||X_new - X_old||_2 = 0.1212500832707278\n",
      "iter# = 1, ||X_new - X_old||_2 = 0.10005826802852813\n",
      "iter# = 2, ||X_new - X_old||_2 = 0.08348756865370392\n",
      "iter# = 3, ||X_new - X_old||_2 = 0.07045052920440503\n",
      "iter# = 4, ||X_new - X_old||_2 = 0.060121145818748216\n",
      "iter# = 5, ||X_new - X_old||_2 = 0.051871737714962014\n",
      "iter# = 6, ||X_new - X_old||_2 = 0.045225252286480194\n",
      "iter# = 7, ||X_new - X_old||_2 = 0.03981908800300554\n",
      "iter# = 8, ||X_new - X_old||_2 = 0.035377560792786034\n",
      "iter# = 9, ||X_new - X_old||_2 = 0.03169090552514103\n",
      "iter# = 10, ||X_new - X_old||_2 = 0.02859925809158737\n",
      "iter# = 11, ||X_new - X_old||_2 = 0.025980457690516393\n",
      "iter# = 12, ||X_new - X_old||_2 = 0.023740788395788987\n",
      "iter# = 13, ||X_new - X_old||_2 = 0.021807980606322448\n",
      "iter# = 14, ||X_new - X_old||_2 = 0.02012594313746435\n",
      "iter# = 15, ||X_new - X_old||_2 = 0.0186508126753671\n",
      "iter# = 16, ||X_new - X_old||_2 = 0.017347999143895818\n",
      "iter# = 17, ||X_new - X_old||_2 = 0.016189978957704392\n",
      "iter# = 18, ||X_new - X_old||_2 = 0.01515464665553692\n",
      "iter# = 19, ||X_new - X_old||_2 = 0.014224081548573854\n",
      "iter# = 20, ||X_new - X_old||_2 = 0.013383621897046772\n",
      "iter# = 21, ||X_new - X_old||_2 = 0.012621166636973201\n",
      "iter# = 22, ||X_new - X_old||_2 = 0.011926645502154757\n",
      "iter# = 23, ||X_new - X_old||_2 = 0.011291613978228853\n",
      "iter# = 24, ||X_new - X_old||_2 = 0.0107089410964194\n",
      "iter# = 25, ||X_new - X_old||_2 = 0.010172566601275803\n",
      "iter# = 26, ||X_new - X_old||_2 = 0.009677310276555223\n",
      "iter# = 27, ||X_new - X_old||_2 = 0.00921872077685186\n",
      "iter# = 28, ||X_new - X_old||_2 = 0.008792954636481715\n",
      "iter# = 29, ||X_new - X_old||_2 = 0.008396678545502812\n",
      "iter# = 30, ||X_new - X_old||_2 = 0.008026989742582698\n",
      "iter# = 31, ||X_new - X_old||_2 = 0.007681350657151199\n",
      "iter# = 32, ||X_new - X_old||_2 = 0.0073575348710297065\n",
      "iter# = 33, ||X_new - X_old||_2 = 0.0070535821584906\n",
      "iter# = 34, ||X_new - X_old||_2 = 0.006767760872664241\n",
      "iter# = 35, ||X_new - X_old||_2 = 0.006498536325233278\n",
      "iter# = 36, ||X_new - X_old||_2 = 0.006244544091171733\n",
      "iter# = 37, ||X_new - X_old||_2 = 0.006004567386525611\n",
      "iter# = 38, ||X_new - X_old||_2 = 0.0057775178332297415\n",
      "iter# = 39, ||X_new - X_old||_2 = 0.005562419053838175\n",
      "iter# = 40, ||X_new - X_old||_2 = 0.005358392640299698\n",
      "iter# = 41, ||X_new - X_old||_2 = 0.005164646121287088\n",
      "iter# = 42, ||X_new - X_old||_2 = 0.004980462617089844\n",
      "iter# = 43, ||X_new - X_old||_2 = 0.004805191923295463\n",
      "iter# = 44, ||X_new - X_old||_2 = 0.004638242807088989\n",
      "iter# = 45, ||X_new - X_old||_2 = 0.004479076335014623\n",
      "iter# = 46, ||X_new - X_old||_2 = 0.004327200079975349\n",
      "iter# = 47, ||X_new - X_old||_2 = 0.004182163079253084\n",
      "iter# = 48, ||X_new - X_old||_2 = 0.004043551435347689\n",
      "iter# = 49, ||X_new - X_old||_2 = 0.003910984468143575\n",
      "iter# = 50, ||X_new - X_old||_2 = 0.003784111340929329\n",
      "iter# = 51, ||X_new - X_old||_2 = 0.0036626080945353955\n",
      "iter# = 52, ||X_new - X_old||_2 = 0.0035461750337475602\n",
      "iter# = 53, ||X_new - X_old||_2 = 0.0034345344184616325\n",
      "iter# = 54, ||X_new - X_old||_2 = 0.003327428419057237\n",
      "iter# = 55, ||X_new - X_old||_2 = 0.003224617301385795\n",
      "iter# = 56, ||X_new - X_old||_2 = 0.003125877811754546\n",
      "iter# = 57, ||X_new - X_old||_2 = 0.00303100173652708\n",
      "iter# = 58, ||X_new - X_old||_2 = 0.002939794614530785\n",
      "iter# = 59, ||X_new - X_old||_2 = 0.0028520745834987905\n",
      "iter# = 60, ||X_new - X_old||_2 = 0.0027676713443568015\n",
      "iter# = 61, ||X_new - X_old||_2 = 0.0026864252293520834\n",
      "iter# = 62, ||X_new - X_old||_2 = 0.0026081863618968443\n",
      "iter# = 63, ||X_new - X_old||_2 = 0.002532813897590281\n",
      "iter# = 64, ||X_new - X_old||_2 = 0.002460175337250844\n",
      "iter# = 65, ||X_new - X_old||_2 = 0.0023901459039602875\n",
      "iter# = 66, ||X_new - X_old||_2 = 0.0023226079771258546\n",
      "iter# = 67, ||X_new - X_old||_2 = 0.002257450577433203\n",
      "iter# = 68, ||X_new - X_old||_2 = 0.002194568897307426\n",
      "iter# = 69, ||X_new - X_old||_2 = 0.0021338638721486564\n",
      "iter# = 70, ||X_new - X_old||_2 = 0.002075241788163294\n",
      "iter# = 71, ||X_new - X_old||_2 = 0.002018613923103737\n",
      "iter# = 72, ||X_new - X_old||_2 = 0.0019638962166451434\n",
      "iter# = 73, ||X_new - X_old||_2 = 0.0019110089675080262\n",
      "iter# = 74, ||X_new - X_old||_2 = 0.0018598765547428473\n",
      "iter# = 75, ||X_new - X_old||_2 = 0.0018104271808918068\n",
      "iter# = 76, ||X_new - X_old||_2 = 0.0017625926349771352\n",
      "iter# = 77, ||X_new - X_old||_2 = 0.0017163080734956737\n",
      "iter# = 78, ||X_new - X_old||_2 = 0.0016715118177800168\n",
      "iter# = 79, ||X_new - X_old||_2 = 0.0016281451662680695\n",
      "iter# = 80, ||X_new - X_old||_2 = 0.0015861522203640744\n",
      "iter# = 81, ||X_new - X_old||_2 = 0.0015454797227121072\n",
      "iter# = 82, ||X_new - X_old||_2 = 0.0015060769068192161\n",
      "iter# = 83, ||X_new - X_old||_2 = 0.001467895357071734\n",
      "iter# = 84, ||X_new - X_old||_2 = 0.0014308888782799756\n",
      "iter# = 85, ||X_new - X_old||_2 = 0.0013950133739728228\n",
      "iter# = 86, ||X_new - X_old||_2 = 0.0013602267327329897\n",
      "iter# = 87, ||X_new - X_old||_2 = 0.0013264887219355556\n",
      "iter# = 88, ||X_new - X_old||_2 = 0.0012937608883097234\n",
      "iter# = 89, ||X_new - X_old||_2 = 0.0012620064647944809\n",
      "iter# = 90, ||X_new - X_old||_2 = 0.0012311902832112512\n",
      "iter# = 91, ||X_new - X_old||_2 = 0.0012012786923160427\n",
      "iter# = 92, ||X_new - X_old||_2 = 0.001172239480832565\n",
      "iter# = 93, ||X_new - X_old||_2 = 0.001144041805106296\n",
      "iter# = 94, ||X_new - X_old||_2 = 0.0011166561210427975\n",
      "iter# = 95, ||X_new - X_old||_2 = 0.0010900541200326208\n",
      "iter# = 96, ||X_new - X_old||_2 = 0.0010642086685777963\n",
      "iter# = 97, ||X_new - X_old||_2 = 0.001039093751372265\n",
      "iter# = 98, ||X_new - X_old||_2 = 0.0010146844175959796\n",
      "iter# = 99, ||X_new - X_old||_2 = 0.0009909567302113474\n",
      "Number of steps: 101\n",
      "iter# = 0, ||X_new - X_old||_2 = 0.1976474554811264\n",
      "iter# = 1, ||X_new - X_old||_2 = 0.04740416302303597\n",
      "iter# = 2, ||X_new - X_old||_2 = 0.02770559865779321\n",
      "iter# = 3, ||X_new - X_old||_2 = 0.02217481413749796\n",
      "iter# = 4, ||X_new - X_old||_2 = 0.01926324646593391\n",
      "iter# = 5, ||X_new - X_old||_2 = 0.017338277843821054\n",
      "iter# = 6, ||X_new - X_old||_2 = 0.015656498124234915\n",
      "iter# = 7, ||X_new - X_old||_2 = 0.014363215012998936\n",
      "iter# = 8, ||X_new - X_old||_2 = 0.013193468211172591\n",
      "iter# = 9, ||X_new - X_old||_2 = 0.012280786630237794\n",
      "iter# = 10, ||X_new - X_old||_2 = 0.01152775305706721\n",
      "iter# = 11, ||X_new - X_old||_2 = 0.010945097921042276\n",
      "iter# = 12, ||X_new - X_old||_2 = 0.010443167033913816\n",
      "iter# = 13, ||X_new - X_old||_2 = 0.009917411582039296\n",
      "iter# = 14, ||X_new - X_old||_2 = 0.009414140530906827\n",
      "iter# = 15, ||X_new - X_old||_2 = 0.00899091837986895\n",
      "iter# = 16, ||X_new - X_old||_2 = 0.008651651629246599\n",
      "iter# = 17, ||X_new - X_old||_2 = 0.008357922192257798\n",
      "iter# = 18, ||X_new - X_old||_2 = 0.008023109560899121\n",
      "iter# = 19, ||X_new - X_old||_2 = 0.007709882334996142\n",
      "iter# = 20, ||X_new - X_old||_2 = 0.007466273434937558\n",
      "iter# = 21, ||X_new - X_old||_2 = 0.007236285968255312\n",
      "iter# = 22, ||X_new - X_old||_2 = 0.006938942464908842\n",
      "iter# = 23, ||X_new - X_old||_2 = 0.006726521130006791\n",
      "iter# = 24, ||X_new - X_old||_2 = 0.006543254730729281\n",
      "iter# = 25, ||X_new - X_old||_2 = 0.006370567305919005\n",
      "iter# = 26, ||X_new - X_old||_2 = 0.006200911288875211\n",
      "iter# = 27, ||X_new - X_old||_2 = 0.006022765667776667\n",
      "iter# = 28, ||X_new - X_old||_2 = 0.005876592969448421\n",
      "iter# = 29, ||X_new - X_old||_2 = 0.005735970921476538\n",
      "iter# = 30, ||X_new - X_old||_2 = 0.005577921424331664\n",
      "iter# = 31, ||X_new - X_old||_2 = 0.005450573201647698\n",
      "iter# = 32, ||X_new - X_old||_2 = 0.005321692559120601\n",
      "iter# = 33, ||X_new - X_old||_2 = 0.005184980972289475\n",
      "iter# = 34, ||X_new - X_old||_2 = 0.00507509348010763\n",
      "iter# = 35, ||X_new - X_old||_2 = 0.004969118086786733\n",
      "iter# = 36, ||X_new - X_old||_2 = 0.004867352096032019\n",
      "iter# = 37, ||X_new - X_old||_2 = 0.004769318231691803\n",
      "iter# = 38, ||X_new - X_old||_2 = 0.004663387142297662\n",
      "iter# = 39, ||X_new - X_old||_2 = 0.004558693912321452\n",
      "iter# = 40, ||X_new - X_old||_2 = 0.004472991198878442\n",
      "iter# = 41, ||X_new - X_old||_2 = 0.004388791669530513\n",
      "iter# = 42, ||X_new - X_old||_2 = 0.004307761235037989\n",
      "iter# = 43, ||X_new - X_old||_2 = 0.004214839254686606\n",
      "iter# = 44, ||X_new - X_old||_2 = 0.004139341496257425\n",
      "iter# = 45, ||X_new - X_old||_2 = 0.004067273999789637\n",
      "iter# = 46, ||X_new - X_old||_2 = 0.003997703848599394\n",
      "iter# = 47, ||X_new - X_old||_2 = 0.003930337763002506\n",
      "iter# = 48, ||X_new - X_old||_2 = 0.003865002657523409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter# = 49, ||X_new - X_old||_2 = 0.003799762160936688\n",
      "iter# = 50, ||X_new - X_old||_2 = 0.0037281212278381885\n",
      "iter# = 51, ||X_new - X_old||_2 = 0.003668980561926363\n",
      "iter# = 52, ||X_new - X_old||_2 = 0.0036117065032780283\n",
      "iter# = 53, ||X_new - X_old||_2 = 0.0035562372660527886\n",
      "iter# = 54, ||X_new - X_old||_2 = 0.0035023719200476845\n",
      "iter# = 55, ||X_new - X_old||_2 = 0.003449998313305178\n",
      "iter# = 56, ||X_new - X_old||_2 = 0.003399032146521304\n",
      "iter# = 57, ||X_new - X_old||_2 = 0.003349400991214487\n",
      "iter# = 58, ||X_new - X_old||_2 = 0.003301037337546303\n",
      "iter# = 59, ||X_new - X_old||_2 = 0.0032508872091258053\n",
      "iter# = 60, ||X_new - X_old||_2 = 0.003199820436212539\n",
      "iter# = 61, ||X_new - X_old||_2 = 0.003152623501686367\n",
      "iter# = 62, ||X_new - X_old||_2 = 0.0031126119095165007\n",
      "iter# = 63, ||X_new - X_old||_2 = 0.0030706357958085084\n",
      "iter# = 64, ||X_new - X_old||_2 = 0.0030297772427028418\n",
      "iter# = 65, ||X_new - X_old||_2 = 0.00298991997032713\n",
      "iter# = 66, ||X_new - X_old||_2 = 0.0029510142058552565\n",
      "iter# = 67, ||X_new - X_old||_2 = 0.0029130193306518997\n",
      "iter# = 68, ||X_new - X_old||_2 = 0.002875899831459587\n",
      "iter# = 69, ||X_new - X_old||_2 = 0.002839623479513816\n",
      "iter# = 70, ||X_new - X_old||_2 = 0.0028041604410958135\n",
      "iter# = 71, ||X_new - X_old||_2 = 0.002769482779288304\n",
      "iter# = 72, ||X_new - X_old||_2 = 0.002735564144420702\n",
      "iter# = 73, ||X_new - X_old||_2 = 0.0027023795649997223\n",
      "iter# = 74, ||X_new - X_old||_2 = 0.0026699052965450994\n",
      "iter# = 75, ||X_new - X_old||_2 = 0.002638118706119729\n",
      "iter# = 76, ||X_new - X_old||_2 = 0.002606998180126678\n",
      "iter# = 77, ||X_new - X_old||_2 = 0.002576523048062911\n",
      "iter# = 78, ||X_new - X_old||_2 = 0.00254667351769128\n",
      "iter# = 79, ||X_new - X_old||_2 = 0.0025174306187024952\n",
      "iter# = 80, ||X_new - X_old||_2 = 0.002488776152919245\n",
      "iter# = 81, ||X_new - X_old||_2 = 0.002460692649672902\n",
      "iter# = 82, ||X_new - X_old||_2 = 0.0024331633253956196\n",
      "iter# = 83, ||X_new - X_old||_2 = 0.0024061720467275422\n",
      "iter# = 84, ||X_new - X_old||_2 = 0.002379703296594735\n",
      "iter# = 85, ||X_new - X_old||_2 = 0.0023537421428854073\n",
      "iter# = 86, ||X_new - X_old||_2 = 0.0023282742093888495\n",
      "iter# = 87, ||X_new - X_old||_2 = 0.0023032856487738423\n",
      "iter# = 88, ||X_new - X_old||_2 = 0.002278763117413849\n",
      "iter# = 89, ||X_new - X_old||_2 = 0.002254693751928258\n",
      "iter# = 90, ||X_new - X_old||_2 = 0.0022310651473375297\n",
      "iter# = 91, ||X_new - X_old||_2 = 0.0022078653367976373\n",
      "iter# = 92, ||X_new - X_old||_2 = 0.0021850827729388215\n",
      "iter# = 93, ||X_new - X_old||_2 = 0.0021627063109531056\n",
      "iter# = 94, ||X_new - X_old||_2 = 0.002140725193781238\n",
      "iter# = 95, ||X_new - X_old||_2 = 0.002119129040269809\n",
      "iter# = 96, ||X_new - X_old||_2 = 0.002097907838462614\n",
      "iter# = 97, ||X_new - X_old||_2 = 0.0020770519506421777\n",
      "iter# = 98, ||X_new - X_old||_2 = 0.0020565521572923203\n",
      "iter# = 99, ||X_new - X_old||_2 = 0.002034365947165598\n",
      "iter# = 100, ||X_new - X_old||_2 = 0.002013288682919795\n",
      "iter# = 101, ||X_new - X_old||_2 = 0.001993291821442919\n",
      "iter# = 102, ||X_new - X_old||_2 = 0.001974057887890416\n",
      "iter# = 103, ||X_new - X_old||_2 = 0.0019552014417118947\n",
      "iter# = 104, ||X_new - X_old||_2 = 0.0019366786790205271\n",
      "iter# = 105, ||X_new - X_old||_2 = 0.0019184690171254997\n",
      "iter# = 106, ||X_new - X_old||_2 = 0.0019005583721722196\n",
      "iter# = 107, ||X_new - X_old||_2 = 0.0018829355710459777\n",
      "iter# = 108, ||X_new - X_old||_2 = 0.0018655909731898276\n",
      "iter# = 109, ||X_new - X_old||_2 = 0.0018485158385564118\n",
      "iter# = 110, ||X_new - X_old||_2 = 0.0018317020252478801\n",
      "iter# = 111, ||X_new - X_old||_2 = 0.0018151418965438653\n",
      "iter# = 112, ||X_new - X_old||_2 = 0.0017988284994144568\n",
      "iter# = 113, ||X_new - X_old||_2 = 0.0017827564984446856\n",
      "iter# = 114, ||X_new - X_old||_2 = 0.0017656192444173051\n",
      "iter# = 115, ||X_new - X_old||_2 = 0.0017490980468663983\n",
      "iter# = 116, ||X_new - X_old||_2 = 0.0017332351379880239\n",
      "iter# = 117, ||X_new - X_old||_2 = 0.0017181175834104544\n",
      "iter# = 118, ||X_new - X_old||_2 = 0.0017033115079194917\n",
      "iter# = 119, ||X_new - X_old||_2 = 0.0016887602067766345\n",
      "iter# = 120, ||X_new - X_old||_2 = 0.0016744434638009697\n",
      "iter# = 121, ||X_new - X_old||_2 = 0.0016603492788170996\n",
      "iter# = 122, ||X_new - X_old||_2 = 0.0016464689810932582\n",
      "iter# = 123, ||X_new - X_old||_2 = 0.0016327956200343004\n",
      "iter# = 124, ||X_new - X_old||_2 = 0.0016193232544842622\n",
      "iter# = 125, ||X_new - X_old||_2 = 0.0016060465928623108\n",
      "iter# = 126, ||X_new - X_old||_2 = 0.0015931984693048835\n",
      "iter# = 127, ||X_new - X_old||_2 = 0.0015820736313820292\n",
      "iter# = 128, ||X_new - X_old||_2 = 0.0015676453629328388\n",
      "iter# = 129, ||X_new - X_old||_2 = 0.0015567923728696358\n",
      "iter# = 130, ||X_new - X_old||_2 = 0.001542734003789389\n",
      "iter# = 131, ||X_new - X_old||_2 = 0.001532206388150806\n",
      "iter# = 132, ||X_new - X_old||_2 = 0.0015185028924120786\n",
      "iter# = 133, ||X_new - X_old||_2 = 0.0015082877585084757\n",
      "iter# = 134, ||X_new - X_old||_2 = 0.0014949253751577595\n",
      "iter# = 135, ||X_new - X_old||_2 = 0.0014850094865695215\n",
      "iter# = 136, ||X_new - X_old||_2 = 0.0014719756300443465\n",
      "iter# = 137, ||X_new - X_old||_2 = 0.0014623464203058333\n",
      "iter# = 138, ||X_new - X_old||_2 = 0.0014496292041741234\n",
      "iter# = 139, ||X_new - X_old||_2 = 0.001439891538273599\n",
      "iter# = 140, ||X_new - X_old||_2 = 0.0014290983210529038\n",
      "iter# = 141, ||X_new - X_old||_2 = 0.0014184118457531646\n",
      "iter# = 142, ||X_new - X_old||_2 = 0.0014078619337992277\n",
      "iter# = 143, ||X_new - X_old||_2 = 0.0013974465726212086\n",
      "iter# = 144, ||X_new - X_old||_2 = 0.0013871632573848067\n",
      "iter# = 145, ||X_new - X_old||_2 = 0.0013770095605812487\n",
      "iter# = 146, ||X_new - X_old||_2 = 0.0013669831206893069\n",
      "iter# = 147, ||X_new - X_old||_2 = 0.0013570816351839289\n",
      "iter# = 148, ||X_new - X_old||_2 = 0.0013473028568765269\n",
      "iter# = 149, ||X_new - X_old||_2 = 0.001337280965113936\n",
      "iter# = 150, ||X_new - X_old||_2 = 0.001327374316788867\n",
      "iter# = 151, ||X_new - X_old||_2 = 0.0013176827047839449\n",
      "iter# = 152, ||X_new - X_old||_2 = 0.0013083326581374826\n",
      "iter# = 153, ||X_new - X_old||_2 = 0.0012991280271805498\n",
      "iter# = 154, ||X_new - X_old||_2 = 0.001290045563524382\n",
      "iter# = 155, ||X_new - X_old||_2 = 0.001281077763829738\n",
      "iter# = 156, ||X_new - X_old||_2 = 0.0012722202219079782\n",
      "iter# = 157, ||X_new - X_old||_2 = 0.001263469702651519\n",
      "iter# = 158, ||X_new - X_old||_2 = 0.001254823560614034\n",
      "iter# = 159, ||X_new - X_old||_2 = 0.001246279491983912\n",
      "iter# = 160, ||X_new - X_old||_2 = 0.0012378354113664915\n",
      "iter# = 161, ||X_new - X_old||_2 = 0.0012294893845834773\n",
      "iter# = 162, ||X_new - X_old||_2 = 0.0012212395893540303\n",
      "iter# = 163, ||X_new - X_old||_2 = 0.0012130842908984391\n",
      "iter# = 164, ||X_new - X_old||_2 = 0.0012050218260407529\n",
      "iter# = 165, ||X_new - X_old||_2 = 0.0011970505923832983\n",
      "iter# = 166, ||X_new - X_old||_2 = 0.0011891690406462796\n",
      "iter# = 167, ||X_new - X_old||_2 = 0.0011813756690531225\n",
      "iter# = 168, ||X_new - X_old||_2 = 0.0011736690190768757\n",
      "iter# = 169, ||X_new - X_old||_2 = 0.0011660476721357628\n",
      "iter# = 170, ||X_new - X_old||_2 = 0.0011585102469288996\n",
      "iter# = 171, ||X_new - X_old||_2 = 0.0011510553972662368\n",
      "iter# = 172, ||X_new - X_old||_2 = 0.001143681810233761\n",
      "iter# = 173, ||X_new - X_old||_2 = 0.0011363882046314467\n",
      "iter# = 174, ||X_new - X_old||_2 = 0.001129173329601907\n",
      "iter# = 175, ||X_new - X_old||_2 = 0.0011220359634194082\n",
      "iter# = 176, ||X_new - X_old||_2 = 0.0011149749123980821\n",
      "iter# = 177, ||X_new - X_old||_2 = 0.0011079890098983363\n",
      "iter# = 178, ||X_new - X_old||_2 = 0.001101077115413748\n",
      "iter# = 179, ||X_new - X_old||_2 = 0.001094238113718463\n",
      "iter# = 180, ||X_new - X_old||_2 = 0.0010874709140709276\n",
      "iter# = 181, ||X_new - X_old||_2 = 0.0010807744494603008\n",
      "iter# = 182, ||X_new - X_old||_2 = 0.001074147675894635\n",
      "iter# = 183, ||X_new - X_old||_2 = 0.0010675895717172335\n",
      "iter# = 184, ||X_new - X_old||_2 = 0.0010610991369501925\n",
      "iter# = 185, ||X_new - X_old||_2 = 0.001054675392667993\n",
      "iter# = 186, ||X_new - X_old||_2 = 0.0010483173803828934\n",
      "iter# = 187, ||X_new - X_old||_2 = 0.0010420241614641614\n",
      "iter# = 188, ||X_new - X_old||_2 = 0.0010357948165545723\n",
      "iter# = 189, ||X_new - X_old||_2 = 0.0010296284450209906\n",
      "iter# = 190, ||X_new - X_old||_2 = 0.0010235241644043322\n",
      "iter# = 191, ||X_new - X_old||_2 = 0.0010174811098952283\n",
      "iter# = 192, ||X_new - X_old||_2 = 0.0010114984338108484\n",
      "iter# = 193, ||X_new - X_old||_2 = 0.0010055753050901561\n",
      "iter# = 194, ||X_new - X_old||_2 = 0.000999710908800591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter# = 195, ||X_new - X_old||_2 = 0.0009939044456499322\n",
      "iter# = 196, ||X_new - X_old||_2 = 0.0009881551315140014\n",
      "iter# = 197, ||X_new - X_old||_2 = 0.0009824621969745987\n",
      "iter# = 198, ||X_new - X_old||_2 = 0.0009768248868655862\n",
      "iter# = 199, ||X_new - X_old||_2 = 0.000971242459832983\n",
      "iter# = 200, ||X_new - X_old||_2 = 0.000965714187900561\n",
      "iter# = 201, ||X_new - X_old||_2 = 0.0009602393560550293\n",
      "iter# = 202, ||X_new - X_old||_2 = 0.0009548172618300968\n",
      "iter# = 203, ||X_new - X_old||_2 = 0.0009494472149155467\n",
      "iter# = 204, ||X_new - X_old||_2 = 0.0009441285367661882\n",
      "iter# = 205, ||X_new - X_old||_2 = 0.0009388605602327905\n",
      "iter# = 206, ||X_new - X_old||_2 = 0.0009336426291895059\n",
      "iter# = 207, ||X_new - X_old||_2 = 0.0009284740981931497\n",
      "iter# = 208, ||X_new - X_old||_2 = 0.0009233543321367001\n",
      "iter# = 209, ||X_new - X_old||_2 = 0.0009182827059224549\n",
      "iter# = 210, ||X_new - X_old||_2 = 0.0009132586041465582\n",
      "iter# = 211, ||X_new - X_old||_2 = 0.0009082814207961676\n",
      "iter# = 212, ||X_new - X_old||_2 = 0.0009033505589507913\n",
      "iter# = 213, ||X_new - X_old||_2 = 0.0008984654304974672\n",
      "iter# = 214, ||X_new - X_old||_2 = 0.0008936254558665829\n",
      "iter# = 215, ||X_new - X_old||_2 = 0.0008888300637542489\n",
      "iter# = 216, ||X_new - X_old||_2 = 0.0008840786908807989\n",
      "iter# = 217, ||X_new - X_old||_2 = 0.0008793707817326954\n",
      "iter# = 218, ||X_new - X_old||_2 = 0.0008747057883288852\n",
      "iter# = 219, ||X_new - X_old||_2 = 0.0008700831699858449\n",
      "iter# = 220, ||X_new - X_old||_2 = 0.0008655023930891073\n",
      "iter# = 221, ||X_new - X_old||_2 = 0.0008609629308697998\n",
      "iter# = 222, ||X_new - X_old||_2 = 0.0008564642631853454\n",
      "iter# = 223, ||X_new - X_old||_2 = 0.0008520058763023354\n",
      "iter# = 224, ||X_new - X_old||_2 = 0.0008475872626791299\n",
      "iter# = 225, ||X_new - X_old||_2 = 0.0008432079207504194\n",
      "iter# = 226, ||X_new - X_old||_2 = 0.0008388673547227656\n",
      "iter# = 227, ||X_new - X_old||_2 = 0.0008345650743622112\n",
      "iter# = 228, ||X_new - X_old||_2 = 0.0008303005947901938\n",
      "iter# = 229, ||X_new - X_old||_2 = 0.0008260734363119073\n",
      "iter# = 230, ||X_new - X_old||_2 = 0.0008218831242561588\n",
      "iter# = 231, ||X_new - X_old||_2 = 0.0008177291888942033\n",
      "iter# = 232, ||X_new - X_old||_2 = 0.0008136111654723668\n",
      "iter# = 233, ||X_new - X_old||_2 = 0.0008095285944813292\n",
      "iter# = 234, ||X_new - X_old||_2 = 0.0008054810224051486\n",
      "iter# = 235, ||X_new - X_old||_2 = 0.0008014680034591239\n",
      "iter# = 236, ||X_new - X_old||_2 = 0.0007974891036132917\n",
      "iter# = 237, ||X_new - X_old||_2 = 0.0007935439104693695\n",
      "iter# = 238, ||X_new - X_old||_2 = 0.000789632061410579\n",
      "iter# = 239, ||X_new - X_old||_2 = 0.0007854311600829197\n",
      "iter# = 240, ||X_new - X_old||_2 = 0.0007813356442254375\n",
      "iter# = 241, ||X_new - X_old||_2 = 0.0007774565901165998\n",
      "iter# = 242, ||X_new - X_old||_2 = 0.0007736490701283115\n",
      "iter# = 243, ||X_new - X_old||_2 = 0.0007698849813407424\n",
      "iter# = 244, ||X_new - X_old||_2 = 0.0007661579756464295\n",
      "iter# = 245, ||X_new - X_old||_2 = 0.0007624654524109831\n",
      "iter# = 246, ||X_new - X_old||_2 = 0.0007588059057604103\n",
      "iter# = 247, ||X_new - X_old||_2 = 0.0007551783016316807\n",
      "iter# = 248, ||X_new - X_old||_2 = 0.0007515818536791618\n",
      "iter# = 249, ||X_new - X_old||_2 = 0.0007480159203669621\n",
      "iter# = 250, ||X_new - X_old||_2 = 0.000744479951254456\n",
      "iter# = 251, ||X_new - X_old||_2 = 0.0007409734566161142\n",
      "iter# = 252, ||X_new - X_old||_2 = 0.0007374959892142289\n",
      "iter# = 253, ||X_new - X_old||_2 = 0.0007340471328391912\n",
      "iter# = 254, ||X_new - X_old||_2 = 0.0007306264948096636\n",
      "iter# = 255, ||X_new - X_old||_2 = 0.0007272337009066121\n",
      "iter# = 256, ||X_new - X_old||_2 = 0.00072386839184607\n",
      "iter# = 257, ||X_new - X_old||_2 = 0.0007205302207511119\n",
      "Number of steps: 259\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Run algorithm\n",
    "epsilon = 1e-3                # Precision parameter\n",
    "iters = 1000\n",
    "eta = 0.1\n",
    "\n",
    "U, S, V = la.svd(X_star)\n",
    "l = np.sum(S)\n",
    "\n",
    "X_IHT, X_list_IHT, f_list_IHT = matrix_IHT(y, A, r, eta, iters, epsilon, True, X_star)\n",
    "X_NN, X_list_NN, f_list_NN = matrix_nuclear_norm_min(y, A, l, eta, iters, epsilon, True, X_star)\n",
    "\n",
    "# Plot\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "xs_IHT = range(len(X_list_IHT))\n",
    "xs_NN = range(len(X_list_NN))\n",
    "\n",
    "plt.plot(xs_IHT, X_list_IHT, '-o', color = '#3399FF', linewidth = 2, alpha = 0.7) # Blue\n",
    "plt.plot(xs_NN, X_list_NN, '-o', color = '#FF6666', linewidth = 2, alpha = 0.7) # Red\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel(r\"$\\|x^\\star - \\widehat{x}\\|_2$\")\n",
    "\n",
    "# Make room for the ridiculously large title.\n",
    "plt.subplots_adjust(top=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
